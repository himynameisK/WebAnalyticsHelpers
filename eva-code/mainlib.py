from yametrics import *
from telegramcli import *


def short_url(url, internal_name=None):
    '''
    –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç —É–¥–∞–ª–µ–Ω–∏–µ –∏–∑ –∑–∞–¥–∞–Ω–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ url –¥–æ–º–µ–Ω —Å–∞–π—Ç–∞ (—Å–æ–∫—Ä–∞—â–∞–µ—Ç –∑–∞–ø–∏—Å—å)
    '''
    if url is None:
        return None
    subs_index = url.find('https://')
    if subs_index != -1:
        sh_url = url[8:]
        if internal_name is None or url.find(internal_name) != -1:
            start = sh_url.find('/')
            if start != -1:
                return sh_url[start:]
            else:
                return url
        else:
            return sh_url
    else:
        return url

def get_translation_dict(path='./translation.csv'):
    d = dict()
    try:
        trans_df = pd.read_csv(path)

        return {i[0][i[0].rfind(':') + 1:] : i[1] for i in trans_df.values}
    except Exception as e:
        print('Failed to get translation')
        print(str(e))
        return dict()


def days_window_to_str(day_window): 
    '''
    –°–∫–ª–æ–Ω—è–µ—Ç –∑–∞–¥–∞–Ω–Ω–æ–µ —á–∏—Å–ª–æ (5 -> '5 –¥–Ω–µ–π', 22 -> '22 –¥–Ω—è' –∏ —Ç.–¥.)
    '''
    if day_window in range(10, 20):
        day_window_str = '{i} –¥–Ω–µ–π'.format(i=day_window)
    elif day_window % 10 == 1:
        day_window_str = '{i} –¥–µ–Ω—å'.format(i=day_window)
    elif (day_window % 10) in [2, 3, 4]:
        day_window_str = '{i} –¥–Ω—è'.format(i=day_window)
    else:
        day_window_str = '{i} –¥–Ω–µ–π'.format(i=day_window)
    return day_window_str


def split_df_by_date(df):
    '''
    –†–∞–∑–±–∏–≤–∞–µ—Ç –∑–∞–¥–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Ñ—Ä–µ–π–º –ø–æ –ø–æ–ª—é 'date' –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å –ø–∞—Ä–∞–º–∏ –∫–ª—é—á-–∑–Ω–∞—á–µ–Ω–∏–µ –≤–∏–¥–∞ "–¥–∞—Ç–∞ : pdDataFrame"
    '''
    df_dict = dict()
    for i in df.groupby('date'):
        df_dict[str(i[0])[:10]] = i[1]
    return df_dict


def validate_404_error_row(row):
    '''
    –§—É–Ω–∫—Ü–∏—è, –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –Ω–∞ –≤—Ö–æ–¥ —Å—Ç—Ä–æ–∫—É —Ç–∞–±–ª–∏—Ü—ã, –ø–æ–ª—É—á–µ–Ω–Ω–æ–π –∏–∑ —è–Ω–¥–µ–∫—Å –º–µ—Ç—Ä–∏–∫–∏ –∏ –ø—Ä–æ–≤–æ–¥–∏—Ç –¥–ª—è –Ω–µ–µ –≤–∞–ª–∏–¥–∞—Ü–∏—é
    –≤ —Å–º—ã—Å–ª–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —ç—Ç–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    '''
    try:
        from requests import get
        return get(row[0], verify=False).status_code
    except Exception as e:
        print('For value {val} exception occured:'.format(val=row))
        print(str(e))
        return 'None'
    
def validate_404_error(val):
    '''
    –§—É–Ω–∫—Ü–∏—è, –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ (url) –∏ –Ω–∞ –µ–≥–æ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–≤–æ–¥–∏—Ç –≤–∞–ª–∏–¥–∞—Ü–∏—é (–≤ —Å–º—ã—Å–ª–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã)
    '''
    try:
        from requests import get
        return get(val, verify=False).status_code
    except Exception as e:
        print('For value {val} exception occured:'.format(val=val))
        print(str(e))
        return 'None'
    

def process_abnormality(abnormal_df, abn_date, day_window, top_abn, sensivity=1, window_df=None, val_name=None, val_f = None, url='dokhodchivo', name='None'):
    '''
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è "–ø–æ–¥–ø–∏—Å—á–∏–∫–∞" —Ç–µ–ª–µ–≥—Ä–∞–º –±–æ—Ç–∞, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—è –∑–∞–¥–∞–Ω–Ω—É—é –∞–Ω–æ—Ä–º–∞–ª—å–Ω—É—é –¥–∞—Ç—É (—Å–æ–¥–µ—Ä–∂–∞—â—É—é ) –∏ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º.
    –ö–æ–Ω–∫—Ä–µ—Ç–Ω–µ–µ:
    
    abnormal_df -- –∫—É—Å–æ—á–µ–∫ —Ç–∞–±–ª–∏—Ü—ã, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π –∑–Ω–∞—á–µ–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã –¥–ª—è –∞–Ω–æ–º–∞–ª—å–Ω–æ–π –¥–∞—Ç—ã
    abn_date    -- –∞–Ω–æ–º–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞, –¥–ª—è –∫–æ—Ç–æ—Ä–æ–π –Ω—É–∂–Ω–æ –ø—Ä–æ–∏–∑–≤–µ—Å—Ç–∏ –æ–±—Ä–∞–±–æ—Ç–∫—É –∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ
    day_window  -- —Ä–∞–∑–º–µ—Ä –æ–∫–Ω–∞, –≤ —Ç–µ—á–µ–Ω–∏–µ –∫–æ—Ç–æ—Ä–æ–≥–æ –±–µ—Ä–µ—Ç—Å—è –º–µ—Ç—Ä–∏–∫–∞ –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è –∞–Ω–æ–º–∞–ª—å–Ω–æ—Å—Ç–µ–π 
    top_abn     -- –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç –≤—ã–≤–µ–¥–µ–Ω—ã –≤ —Ç–µ–ª–µ–≥—Ä–∞–º (—Ç–æ–ø –ø–æ –º–µ—Ç—Ä–∏–∫–µ)
    sensivity   -- —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ –∞–Ω–æ–º–∞–ª–∏–π
    window_df   -- —Ç–∞–±–ª–∏—Ü–∞, —Å–æ–¥–µ—Ä–∂–∞—â–∞—è –º–µ—Ç—Ä–∏–∫—É –∑–∞ –≤–µ—Å—å –ø–µ—Ä–∏–æ–¥ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π (day_window). –ï—Å–ª–∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω–∞, –∏–∑–º–µ–Ω–µ–Ω–∏–µ –Ω–µ —Ñ–∏–∫—Å–∏—Ä—É–µ—Ç—Å—è
    val_name    -- –Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏, –∫–æ—Ç–æ—Ä–∞—è –±—É–¥–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—Å—è —Å —É–∫–∞–∑–∞–Ω–Ω–æ–π –º–µ—Ç—Ä–∏–∫–æ–π 
    val_f       -- –Ω–∞–∑–≤–∞–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏, –∫–æ—Ç–æ—Ä–∞—è –±—É–¥–µ—Ç –≤—ã–∑—ã–≤–∞—Ç—å—Å—è –¥–ª—è –∑–∞–¥–∞–Ω–Ω–æ–π –º–µ—Ç—Ä–∏–∫–∏ 
    
    
    '''

    def calculate_difference(df_tar):
        DIGITS_AFTER_POINT = 2
        df_tar_copy = df_tar.copy()
        df_tar_copy['date'] = df_tar_copy['date'].apply(lambda x: str(x)[:10])
        total_metric = df_tar_copy.groupby('date').sum()[:-1].values
        
        window_avg = total_metric.sum() / len(total_metric)
        
        last_day = total_metric[-1]
        
        diff = float(last_day / window_avg) - 1
        rounded_diff = round(diff * 100 * 10 ** DIGITS_AFTER_POINT) / 10 ** DIGITS_AFTER_POINT
        return ('+' if rounded_diff > 0 else '') + str(rounded_diff) + "%"    

    SENSIVITY_DECODE = {'0': '–ù–∏–∑–∫–∞—è', '1' : '–°—Ä–µ–¥–Ω—è—è', '2' : '–í—ã—Å–æ–∫–∞—è'}
    
    ab_df = split_df_by_date(abnormal_df)[abn_date].copy()
    date_str = abn_date
    date_from = (datetime.strptime(abn_date, '%Y-%m-%d') - timedelta(day_window)).strftime('%Y-%m-%d')
    
    descr_list = []

    descr_list.append('<b>–°–∞–π—Ç</b>: {site}'.format(site=url))
    descr_list.append('<b>–ü–µ—Ä–∏–æ–¥</b>: —Å {date_from} –ø–æ {date_to} –≤ –æ–∫–Ω–µ –∑–∞ {day_window_string}:'.format(
                                                                          date_from=date_from,
                                                                          date_to=date_str, 
                                                                          day_window_string=days_window_to_str(day_window)))
    descr_list.append('<b>–ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å</b>: {sens}'.format(sens=SENSIVITY_DECODE.get(sensivity, str(sensivity) + 'œÉ')))
    descr_list.append('<b>–ü—Ä–æ–≤–µ—Ä–∫–∞</b>: {check_name}'.format(check_name=name))
    descr_list.append('<b>–ß–∞—Å—Ç–æ—Ç–∞</b>: 1 —Ä–∞–∑ –≤ –¥–µ–Ω—å')
    #descr_list.append('<b>–ò–∑–º–µ–Ω–µ–Ω–∏–µ</b>: {diff}'.format(diff=calculate_difference()))
    
    diff = calculate_difference(window_df)
    if not (window_df is None): 
        change_name = '–£–≤–µ–ª–∏—á–µ–Ω–∏–µ' if diff[0] == '+' else '–°–Ω–∏–∂–µ–Ω–∏–µ'
        descr_list.append('<b>{name}</b>: {diff}'.format(name=change_name, diff=calculate_difference(window_df)))   

    #message = "\n".join([msg_hello, msg_range, msg_sensivity, msg_check])
    message = "\n".join(descr_list)
    
    metric_column = ab_df.columns[-1]

    ab_df[metric_column] = ab_df[metric_column].map(int)
    

    if not(val_f is None) and val_name == '–°—Ç–∞—Ç—É—Å —Å–µ–π—á–∞—Å':
        url_pos = list(ab_df.columns).index("URL")
        ab_df["status"] = ab_df.apply(lambda x: val_f(list(x)[1:]), axis=1)
        ab_df_top = ab_df[ab_df["status"] == 404].sort_values(metric_column, ascending=False)[ab_df.columns[1:]].iloc[:top_abn].values
    else:
        ab_df_top = ab_df.sort_values(metric_column, ascending=False)[ab_df.columns[1:]].iloc[:top_abn].values
    str_table = ''
    url_template = '<a href="{src}">{text}</a>'
    
    translation_dict_const = {'URL' : '–°—Ç—Ä–∞–Ω–∏—Ü–∞', 'pageviews' : '–ü—Ä–æ—Å–º–æ—Ç—Ä—ã', 'referer' : '–†–µ—Ñ–µ—Ä–µ—Ä', 'visits' : '–í–∏–∑–∏—Ç—ã'}

    translation_dict = {**get_translation_dict(), **translation_dict_const}

    column_names = [translation_dict.get(name, name) for name in ab_df.columns[1:]]
    
    cv_pair = '<b>{column}</b>:\n{value}\n'
    
    #str_table += ['_______\n' + ''.join([cv_pair.format(column=str(column_names[val[0]]), value=str(val[1])) for val in enumerate(row)]) for row in ab_df_top]
    limit = -1 if 'status' in ab_df.columns else len(ab_df_top[0])
    for row in ab_df_top:
        row_message = []
        for val in enumerate(row[:limit]):
            if str(val[1]).find('https://') != -1:
                value = url_template.format(src=val[1],text=short_url(val[1], url))
            else:
                value = str(val[1])
            column = column_names[val[0]] 
            row_message.append(cv_pair.format(column=column, value=value))
            
        if val_name is not None and val_f is not None:
            row_message.append(cv_pair.format(column=val_name, value=val_f(row)))
        
        str_table += '_______\n' + ''.join(row_message)
 
    message_top = '\n<i>–¢–æ–ø {top_count} –ø—Ä–æ–∏–∑–æ—à–µ–¥—à–∏—Ö —Å–æ–±—ã—Ç–∏–π –ø–æ —á–∞—Å—Ç–æ—Ç–µ:</i>\n'
    message_ending = '_______\n–ü–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç –≤–æ –≤–ª–æ–∂–µ–Ω–∏–∏.'
    final_message = message + '\n' + message_top.format(top_count=top_abn) + str_table + message_ending
    print(ab_df.columns)
    print("before")
    if val_name == '–°—Ç–∞—Ç—É—Å —Å–µ–π—á–∞—Å': 
         ab_df.drop(columns=['status'], axis=1, inplace=True)
    print(ab_df.columns)
    print("after")
    return final_message



def check_and_send_message(name, check_name, url, counter, day_window, top_count, sensivity, accuracy, metrics, dimensions, 
                           filters, validity_function, SAVED_CHAT_ID, OAUTH_TOKEN, API_TOKEN, receiver_list, warn_receivers, mute_na):
    '''
    –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç –ø—Ä–æ–≤–µ—Ä–∫—É –∑–∞–¥–∞–Ω–Ω–æ–π –º–µ—Ç—Ä–∏–∫–∏ –ø–æ —Å–ª–µ–¥—É—é—â–∏–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º
    
    name -- –Ω–∞–∑–≤–∞–Ω–∏–µ —Å–∞–π—Ç–∞
    check name -- –Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
    url -- url, –¥–ª—è –∫–æ—Ç–æ—Ä–æ–≥–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—Å—è –ø—Ä–æ–≤–µ—Ä–∫–∞
    counter -- counter —Å–∞–π—Ç–∞, –¥–ª—è –∫–æ—Ç–æ—Ä–æ–≥–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –ø—Ä–æ–≤–µ—Ä–∫–∞ –º–µ—Ç—Ä–∏–∫–∏
    day_window -- —Ä–∞–∑–º–µ—Ä –æ–∫–Ω–∞ (–≤ –¥–Ω—è—Ö) –¥–ª—è –∫–æ—Ç–æ—Ä–æ–≥–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—Å—è –ø—Ä–æ–≤–µ—Ä–∫–∞
    top_count -- –∫–∞–∫–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ 
    SAVED_CHAT_ID -- —Å–ª–æ–≤–∞—Ä—å –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤ —á–∞—Ç–∞, –∫–æ—Ç–æ—Ä—ã–º –±—É–¥–µ—Ç –ø–µ—Ä–µ–¥–∞–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ 
    OAUTH_TOKEN   -- –¢–æ–∫–µ–Ω —è–Ω–¥–µ–∫—Å –º–µ—Ç—Ä–∏–∫–∏
    API_TOKEN     -- –¢–æ–∫–µ–Ω Telegram API –±–æ—Ç–∞, —á–µ—Ä–µ–∑ –∫–æ—Ç–æ—Ä–æ–≥–æ –±—É–¥–µ—Ç –ø–µ—Ä–µ–¥–∞–Ω –æ—Ç—á–µ—Ç 
    '''

    top_count = int(top_count)
    day_window = int(day_window)
    
    is_anomalies_detected = False
    
        # 1. –ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –∑–∞ N –¥–Ω–µ–π –Ω–∞—á–∏–Ω–∞—è —Å —Å–µ–≥–æ–¥–Ω—è—à–Ω–µ–≥–æ –¥–ª—è 

    VALIDITY_FUNCTIONS = {"status_code" : {
        "value_name" : '–°—Ç–∞—Ç—É—Å —Å–µ–π—á–∞—Å',
        "row_function" : validate_404_error_row,
        "function" : validate_404_error
    }}

    # 2.
    print(counter)
    print(metrics)
    print(dimensions)
    print(filters)
    df_target = get_parametrized_metrics(day_window, counter, metrics, dimensions, filters, accuracy, OAUTH_TOKEN=OAUTH_TOKEN)

    abnormal_dates = get_abnormal_dates(df_target, sensivity)
    abnormal_df = df_target[df_target['date'].isin(abnormal_dates)]

    abnormal_dates_str = [i.strftime('%Y-%m-%d') for i in abnormal_dates]

    all_found_dates_str = {i[0] for i in df_target.values}
    
    try:
        date_does_exist = (datetime.now() - timedelta(1)).strftime('%Y-%m-%d') in [i.strftime('%Y-%m-%d') for i in all_found_dates_str]
        
        if not date_does_exist: 
            try: 
                print('APPENDING WITH NULL ROW')
                def append_with_nulls(df):
                    date = (datetime.now() - timedelta(1)).strftime('%Y-%m-%d')
                    return df.append(pd.DataFrame([[date] + [None] * (len(df.iloc[0]) - 2) + [0]], columns=df.columns))
                df_target = append_with_nulls(df_target)
                abnormal_df = append_with_nulls(abnormal_df)
                date_does_exist = True
            except Exception as e:
                print("##########################")
                print("Exception occured during row append with null row")
                date_does_exist = False
    except Exception as e:
        date_does_exist = False
        print(df_target)
        #raise e
    if not date_does_exist:
        message_list = ['<b>–î–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ "{check_name}" —Å–∞–π—Ç–∞ {url} –¥–∞–Ω–Ω—ã—Ö –∑–∞ {date} –Ω–µ –±—ã–ª–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ</b>'.format(
            check_name=check_name,
            url=url,
            date=(datetime.now() - timedelta(1)).strftime('%Y-%m-%d')
        )]
        
        logfilename = './log/{name}_{date}.xls'.format(
            date=datetime.now().strftime('%Y-%m-%d-%H-%M-%S'),
            name=name
        )
        try:
            df_target['date'] = df_target['date'].apply(lambda x: x.strftime('%Y-%m-%d'))
            df_target.to_excel(logfilename, index=False)

            file_list = [logfilename]
        except Exception as e:
            #raise e
            message_list = ['<b>–î–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ "{check_name}" —Å–∞–π—Ç–∞ {url} –¥–∞–Ω–Ω—ã—Ö –Ω–µ –±—ã–ª–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ.</b>'.format(check_name=check_name,url=url)]
            file_list = ['']
        client = TelegramClient(API_TOKEN)
        for receiver in receiver_list:
            for i in zip(message_list, file_list):
                print('############################################')
                print(client.sendMessage(receiver, i[0]))
                client.sendDocument(receiver, i[1])
                print('############################################')
        return 
    if (datetime.now() - timedelta(1)).strftime('%Y-%m-%d') in abnormal_dates_str:
        message_list = ['–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –∞–Ω–æ–º–∞–ª–∏—è üôà. –ü–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç –≤–æ –≤–ª–æ–∂–µ–Ω–∏–∏'.format(name=name)]
        file_list = ['']
        is_anomalies_detected = True
    else:
        message_list = ['–î–ª—è —Å–∞–π—Ç–∞ {name} –∑–∞ –≤—á–µ—Ä–∞—à–Ω–∏–π –¥–µ–Ω—å –∞–Ω–æ–º–∞–ª–∏–π –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ! –ü–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç –≤–æ –≤–ª–æ–∂–µ–Ω–∏–∏'.format(name=name)]
        file_list = ['']

    # 3. –†–∞–∑–≤–∏–ª–∫–∞: –µ—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É—é—Ç –∞–Ω–æ–º–∞–ª–∏–∏, –æ –Ω–∏—Ö —Å—Ç–æ–∏—Ç —Å–æ–æ–±—â–∏—Ç—å (–∞ —Ç–∞–∫ –∂–µ —Å—Ä–µ–∑ —Ç–æ–ø 10 —Ä–µ—Ñ–µ—Ä–æ–≤, –ø–µ—Ä–µ–≤–æ–¥—è—â–∏—Ö –Ω–∞ 404)

    #abnormalities = len(abnormal_dates)
    if (datetime.now() - timedelta(1)).strftime('%Y-%m-%d') in abnormal_dates_str or mute_na == "0":
        abnormal_date = (datetime.now() - timedelta(1)).strftime('%Y-%m-%d')
        abnormal_df = df_target[df_target['date'].isin([pd.Timestamp((datetime.now() - timedelta(1)).strftime('%Y-%m-%d'))])]

        date_df_dict = split_df_by_date(abnormal_df)
    
        validate_f = None
        validate_name = None
        validate_f_row = None
        if not VALIDITY_FUNCTIONS.get(validity_function, None) is None:
            validate_name = VALIDITY_FUNCTIONS.get(validity_function, None).get('value_name')
            validate_f = VALIDITY_FUNCTIONS.get(validity_function, None).get('function')
            validate_f_row = VALIDITY_FUNCTIONS.get(validity_function, None).get('row_function')
    
        message = process_abnormality(abnormal_df, abnormal_date, day_window, top_count, sensivity, df_target, validate_name, validate_f_row, url, check_name)
        message_list.append(message)
        saved_filename = './{name}_{date}.xls'.format(name=name, date=abnormal_date)
        date_df_dict[abnormal_date]['date'] = date_df_dict[abnormal_date]['date'].apply(lambda x: x.strftime('%Y-%m-%d'))
    
        if not(validate_f is None):
            date_df_dict[abnormal_date]['status'] = date_df_dict[abnormal_date]['URL'].apply(lambda x: validate_f(x))
    
        metric = [i for i in ["pageviews", "visits"] if i in date_df_dict[abnormal_date].columns]    
        date_df_dict[abnormal_date].sort_values(metric, ascending=False).to_excel(saved_filename, index=False)
        file_list.append(saved_filename)

    # –ü–æ—Å—Ç–æ—è–Ω–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª–æ–≥–∞ –º–æ–∂–Ω–æ –æ—Ç–∫–ª—é—á–∏—Ç—å –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω–æ–º —Ñ–∞–π–ª–µ.

        logfilename = './log/{name}_{date}.xls'.format(
            date=datetime.now().strftime('%Y-%m-%d-%H-%M-%S'),
            name=name
        )
        df_target['date'] = df_target['date'].apply(lambda x: x.strftime('%Y-%m-%d'))

        metric = [i for i in ["pageviews", "visits"] if i in df_target.columns]
        df_target.sort_values(metric, ascending=False).to_excel(logfilename, index=False)

    # 4. –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–±–æ—Ç—ã –≤—Å–µ–º –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞–º

        client = TelegramClient(API_TOKEN)

        for receiver in receiver_list:
            for i in zip(message_list, file_list):
                print(i)
                client.sendMessage(receiver, i[0])
                client.sendDocument(receiver, i[1])
                
        if is_anomalies_detected:
            for receiver in warn_receivers:
                for i in zip(message_list, file_list):
                    print(i)
                    client.sendMessage(receiver, i[0])
                    client.sendDocument(receiver, i[1])
            
